{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4af253f-f41f-4f8b-9b42-d0853cb4f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from math import e\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import data_cleaning_functions as dcf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d4c29a-96bb-4fae-ba30-ab67f8612719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet</th>\n",
       "      <th>keyword</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1396047477695029249</td>\n",
       "      <td>2021-05-22 10:17:10+00:00</td>\n",
       "      <td>Tava t√£o feliz c o apartamento mas acho q √© golpe</td>\n",
       "      <td>feliz</td>\n",
       "      <td>positive</td>\n",
       "      <td>tav tao apart ach golp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1396047411047542785</td>\n",
       "      <td>2021-05-22 10:16:54+00:00</td>\n",
       "      <td>@rita_castro1 Bom dia Sweetie!! S√°bado feliz!!...</td>\n",
       "      <td>feliz</td>\n",
       "      <td>positive</td>\n",
       "      <td>bom dia sweti ! sab ! ‚òï</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1396047195921604611</td>\n",
       "      <td>2021-05-22 10:16:03+00:00</td>\n",
       "      <td>Bom dia e um feliz s√°bado a todos ‚úåüèºüíúüçÄ. üòòüòò htt...</td>\n",
       "      <td>feliz</td>\n",
       "      <td>positive</td>\n",
       "      <td>bom dia sab tod ‚úå</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1396046918153904128</td>\n",
       "      <td>2021-05-22 10:14:57+00:00</td>\n",
       "      <td>Eu estou t√£o feliz pela Hande ela merece tudo !</td>\n",
       "      <td>feliz</td>\n",
       "      <td>positive</td>\n",
       "      <td>tao hand merec tud !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1396045926016368642</td>\n",
       "      <td>2021-05-22 10:11:00+00:00</td>\n",
       "      <td>Estou tao feliz finalmente em Castelo Branco c...</td>\n",
       "      <td>feliz</td>\n",
       "      <td>positive</td>\n",
       "      <td>tao final castel branc xuxu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23327</th>\n",
       "      <td>1397872771640827908</td>\n",
       "      <td>2021-05-27 11:10:14+00:00</td>\n",
       "      <td>Eu: detesto musicais ü§Æü§Æü§Æü§Æ\\n\\nAlso eu a dois mi...</td>\n",
       "      <td>detesto OR detestei</td>\n",
       "      <td>negative</td>\n",
       "      <td>music als doi minut episodi music anatom grey ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23328</th>\n",
       "      <td>1397867369276579840</td>\n",
       "      <td>2021-05-27 10:48:46+00:00</td>\n",
       "      <td>Detesto est√° situa√ß√£o poha</td>\n",
       "      <td>detesto OR detestei</td>\n",
       "      <td>negative</td>\n",
       "      <td>situ poh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23329</th>\n",
       "      <td>1397839222883688449</td>\n",
       "      <td>2021-05-27 08:56:55+00:00</td>\n",
       "      <td>Que linda noite de sono ao sonhar com a pessoa...</td>\n",
       "      <td>detesto OR detestei</td>\n",
       "      <td>negative</td>\n",
       "      <td>lind noit son sonh pesso conhec faculdad ent ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23330</th>\n",
       "      <td>1397833381099061248</td>\n",
       "      <td>2021-05-27 08:33:43+00:00</td>\n",
       "      <td>@Joaohpr Tamb√©m detesto e evito sempre que exi...</td>\n",
       "      <td>detesto OR detestei</td>\n",
       "      <td>negative</td>\n",
       "      <td>evit sempr exist altern fac tap ryana ra tem‚Ä¶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23331</th>\n",
       "      <td>1397823272058855425</td>\n",
       "      <td>2021-05-27 07:53:33+00:00</td>\n",
       "      <td>Eu adoro roupa, adoro moda.. Mas trabalhar num...</td>\n",
       "      <td>detesto OR detestei</td>\n",
       "      <td>negative</td>\n",
       "      <td>ador roup ador mod trabalh loj roup lid pesso ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22842 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                 created_at  \\\n",
       "0      1396047477695029249  2021-05-22 10:17:10+00:00   \n",
       "1      1396047411047542785  2021-05-22 10:16:54+00:00   \n",
       "2      1396047195921604611  2021-05-22 10:16:03+00:00   \n",
       "3      1396046918153904128  2021-05-22 10:14:57+00:00   \n",
       "4      1396045926016368642  2021-05-22 10:11:00+00:00   \n",
       "...                    ...                        ...   \n",
       "23327  1397872771640827908  2021-05-27 11:10:14+00:00   \n",
       "23328  1397867369276579840  2021-05-27 10:48:46+00:00   \n",
       "23329  1397839222883688449  2021-05-27 08:56:55+00:00   \n",
       "23330  1397833381099061248  2021-05-27 08:33:43+00:00   \n",
       "23331  1397823272058855425  2021-05-27 07:53:33+00:00   \n",
       "\n",
       "                                                   tweet              keyword  \\\n",
       "0      Tava t√£o feliz c o apartamento mas acho q √© golpe                feliz   \n",
       "1      @rita_castro1 Bom dia Sweetie!! S√°bado feliz!!...                feliz   \n",
       "2      Bom dia e um feliz s√°bado a todos ‚úåüèºüíúüçÄ. üòòüòò htt...                feliz   \n",
       "3        Eu estou t√£o feliz pela Hande ela merece tudo !                feliz   \n",
       "4      Estou tao feliz finalmente em Castelo Branco c...                feliz   \n",
       "...                                                  ...                  ...   \n",
       "23327  Eu: detesto musicais ü§Æü§Æü§Æü§Æ\\n\\nAlso eu a dois mi...  detesto OR detestei   \n",
       "23328                         Detesto est√° situa√ß√£o poha  detesto OR detestei   \n",
       "23329  Que linda noite de sono ao sonhar com a pessoa...  detesto OR detestei   \n",
       "23330  @Joaohpr Tamb√©m detesto e evito sempre que exi...  detesto OR detestei   \n",
       "23331  Eu adoro roupa, adoro moda.. Mas trabalhar num...  detesto OR detestei   \n",
       "\n",
       "         target                                        clean_tweet  \n",
       "0      positive                             tav tao apart ach golp  \n",
       "1      positive                            bom dia sweti ! sab ! ‚òï  \n",
       "2      positive                                  bom dia sab tod ‚úå  \n",
       "3      positive                               tao hand merec tud !  \n",
       "4      positive                        tao final castel branc xuxu  \n",
       "...         ...                                                ...  \n",
       "23327  negative  music als doi minut episodi music anatom grey ...  \n",
       "23328  negative                                           situ poh  \n",
       "23329  negative    lind noit son sonh pesso conhec faculdad ent ta  \n",
       "23330  negative      evit sempr exist altern fac tap ryana ra tem‚Ä¶  \n",
       "23331  negative  ador roup ador mod trabalh loj roup lid pesso ...  \n",
       "\n",
       "[22842 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = open(\"data/df\", \"rb\")\n",
    "df = pickle.load(infile)\n",
    "infile.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fecad59d-f676-4b6e-9db3-e64b1b0f12fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = open(\"data/vectorizer\", \"rb\")\n",
    "vectorizer = pickle.load(infile)\n",
    "infile.close()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0169918-404e-4c4c-b584-880c034009d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab',\n",
       " 'abac',\n",
       " 'abacat',\n",
       " 'abacax',\n",
       " 'abaf',\n",
       " 'abaix',\n",
       " 'abal',\n",
       " 'aban',\n",
       " 'abandon',\n",
       " 'abat']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names()\n",
    "vocabulary[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5a32b3d-ce80-499d-a978-02da63d4ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"data/vocabulary\", 'wb')\n",
    "pickle.dump(vocabulary, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5c40ade-4a68-4cdb-8726-4735cd7bf207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22842x12569 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 150810 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = open(\"data/doc_term_matrix\", \"rb\")\n",
    "doc_term_matrix = pickle.load(infile)\n",
    "infile.close()\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "964ce8b2-e5a7-4eb6-8061-c96c0ba2d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.74%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted negative</th>\n",
       "      <th>predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actually negative</th>\n",
       "      <td>596</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actually positive</th>\n",
       "      <td>385</td>\n",
       "      <td>2773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   predicted negative  predicted positive\n",
       "actually negative                 596                 815\n",
       "actually positive                 385                2773"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "\n",
    "X = doc_term_matrix\n",
    "y = np.where(df[\"target\"]==\"positive\", 1, 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=0.8)\n",
    "\n",
    "model_multinomialNB = MultinomialNB(fit_prior=True)\n",
    "model_multinomialNB.fit(X_train, y_train)\n",
    "\n",
    "# Model testing\n",
    "\n",
    "pred_values = model_multinomialNB.predict(X_test)\n",
    "     \n",
    "print(f\"Accuracy: {round(accuracy_score(pred_values, y_test)*100, 2)}%\")\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, pred_values))\n",
    "conf_matrix.columns = [\"predicted negative\", \"predicted positive\"]\n",
    "conf_matrix.index = [\"actually negative\", \"actually positive\"]\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4861afac-b950-4439-be4f-82c10d81bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model tends to favor predicting positive sentiment; it's not very good at predicting negative \n",
    "# tweets. Which makes sense, because the training set was imbalanced (almost twice as many positive tweets \n",
    "# as negative) and the naive bayes model uses prior probabilities in its classification which are calculated \n",
    "# based on the distribution of the training dataset. This is something that could be improved by collecting \n",
    "# more tweets with negative keywords to balance the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07bd5f-8698-4ed5-ad16-e787f71a9dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d777e34-191b-4a02-bdb4-85f4acee6ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"data/model_multinomialNB\", 'wb')\n",
    "pickle.dump(model_multinomialNB, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f2d6cd8-2805-4160-92f8-f12c6b12b2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_p_negative</th>\n",
       "      <th>log_p_positive</th>\n",
       "      <th>p_negative</th>\n",
       "      <th>p_positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>-9.869483</td>\n",
       "      <td>-10.068515</td>\n",
       "      <td>0.549594</td>\n",
       "      <td>0.450406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abac</th>\n",
       "      <td>-10.968095</td>\n",
       "      <td>-10.761662</td>\n",
       "      <td>0.448574</td>\n",
       "      <td>0.551426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacat</th>\n",
       "      <td>-10.274948</td>\n",
       "      <td>-10.356197</td>\n",
       "      <td>0.520301</td>\n",
       "      <td>0.479699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacax</th>\n",
       "      <td>-10.968095</td>\n",
       "      <td>-10.761662</td>\n",
       "      <td>0.448574</td>\n",
       "      <td>0.551426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaf</th>\n",
       "      <td>-10.968095</td>\n",
       "      <td>-11.454809</td>\n",
       "      <td>0.619332</td>\n",
       "      <td>0.380668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‚ÑÇ‚Ñô</th>\n",
       "      <td>-10.968095</td>\n",
       "      <td>-10.761662</td>\n",
       "      <td>0.448574</td>\n",
       "      <td>0.551426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‚Ñï‚ÑÇ‚Ñï</th>\n",
       "      <td>-10.968095</td>\n",
       "      <td>-10.761662</td>\n",
       "      <td>0.448574</td>\n",
       "      <td>0.551426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‚Ñô‚Ñù</th>\n",
       "      <td>-10.968095</td>\n",
       "      <td>-10.761662</td>\n",
       "      <td>0.448574</td>\n",
       "      <td>0.551426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ïä§Ìä∏Î†àÏù¥ÌÇ§Ï¶à</th>\n",
       "      <td>-10.968095</td>\n",
       "      <td>-10.761662</td>\n",
       "      <td>0.448574</td>\n",
       "      <td>0.551426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ï†úÏù¥ÌÅ¨</th>\n",
       "      <td>-10.968095</td>\n",
       "      <td>-10.761662</td>\n",
       "      <td>0.448574</td>\n",
       "      <td>0.551426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12569 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_p_negative log_p_positive p_negative p_positive\n",
       "word                                                      \n",
       "ab          -9.869483     -10.068515   0.549594   0.450406\n",
       "abac       -10.968095     -10.761662   0.448574   0.551426\n",
       "abacat     -10.274948     -10.356197   0.520301   0.479699\n",
       "abacax     -10.968095     -10.761662   0.448574   0.551426\n",
       "abaf       -10.968095     -11.454809   0.619332   0.380668\n",
       "...               ...            ...        ...        ...\n",
       "‚ÑÇ‚Ñô         -10.968095     -10.761662   0.448574   0.551426\n",
       "‚Ñï‚ÑÇ‚Ñï        -10.968095     -10.761662   0.448574   0.551426\n",
       "‚Ñô‚Ñù         -10.968095     -10.761662   0.448574   0.551426\n",
       "Ïä§Ìä∏Î†àÏù¥ÌÇ§Ï¶à     -10.968095     -10.761662   0.448574   0.551426\n",
       "Ï†úÏù¥ÌÅ¨        -10.968095     -10.761662   0.448574   0.551426\n",
       "\n",
       "[12569 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting sentiment polarity of new text\n",
    "\n",
    "# First, I will build a dataframe with the probabilities (per word) of being in the positive or negative \n",
    "# subsets of the training dataset.\n",
    "\n",
    "feature_log_probs_df = (pd.DataFrame([vocabulary, \n",
    "                                      model_multinomialNB.feature_log_prob_[0], \n",
    "                                      model_multinomialNB.feature_log_prob_[1]])\n",
    "                        .transpose()\n",
    "                        .rename(columns={0:\"word\", 1:\"log_p_negative\", 2:\"log_p_positive\"})\n",
    "                        .set_index(\"word\"))\n",
    "\n",
    "feature_log_probs_df[\"p_negative\"] = e**feature_log_probs_df[\"log_p_negative\"] / (e**feature_log_probs_df[\"log_p_negative\"] + e**feature_log_probs_df[\"log_p_positive\"])\n",
    "feature_log_probs_df[\"p_positive\"] = e**feature_log_probs_df[\"log_p_positive\"] / (e**feature_log_probs_df[\"log_p_negative\"] + e**feature_log_probs_df[\"log_p_positive\"])\n",
    "feature_log_probs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31d1bda8-acb1-4085-8459-64bd2ef697ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"data/feature_log_probs_df\", 'wb')\n",
    "pickle.dump(feature_log_probs_df, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c0b6c4-8667-4c53-911c-abfbd2ec3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this table done, we can build the sentiment predictor function:\n",
    "\n",
    "def sentiment_predictor(text, extended = False):\n",
    "    \"\"\"This function returns the sentiment polarity predicted by a Naive Bayes model trained on a dataset of \n",
    "    tweets. If extended is set to True, it also returns the probabilities per word of being in the negative \n",
    "    or positive subsets of the training dataset.\n",
    "    \n",
    "    Notes on the extended results: \n",
    "    \n",
    "    Some words that are present in the input text might not appear in the extended results table. This \n",
    "    is due to one of three reasons:\n",
    "    - the word is one of the keywords used in building the training dataset\n",
    "    - the word is a stopword (a list of words in portuguese that are so common that they don't contribute \n",
    "    much meaning to the sentiment analysis)\n",
    "    - the word was not present in the training dataset\n",
    "    \n",
    "    Sometimes, the average of the probabilities in the extended results table would suggest that the text \n",
    "    should be considered negative but the result is positive. This is due to the fact that the training\n",
    "    dataset was imbalanced, containing more positive tweets than negative ones. This ends up favoring\n",
    "    positive classifications in edge cases.\n",
    "    \"\"\"\n",
    "    processed_text = dcf.remove_stopwords(dcf.clean_up_tweets(text), dcf.processed_stopwords)\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    count_vectorizer.fit_transform([processed_text])\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "\n",
    "    text_vector = [1 if i in words else 0 for i in vocabulary]\n",
    "    prediction = model_multinomialNB.predict([text_vector])[0]\n",
    "    \n",
    "    if not extended:\n",
    "\n",
    "        if prediction == 0:\n",
    "            print(\"Negative\")\n",
    "            return(0)\n",
    "        else:\n",
    "            print(\"Positive\")\n",
    "            return(1)\n",
    "    else:\n",
    "        \n",
    "        if prediction == 0:\n",
    "            print(\"Negative\")\n",
    "        else:\n",
    "            print(\"Positive\")\n",
    "\n",
    "        words = []\n",
    "        neg_probs = []\n",
    "        pos_probs = []\n",
    "\n",
    "        for word in processed_text.split(\" \"):\n",
    "            words.append(word)\n",
    "            neg_probs.append(feature_log_probs_df.loc[word, \"p_negative\"])\n",
    "            pos_probs.append(feature_log_probs_df.loc[word, \"p_positive\"])\n",
    "\n",
    "        word_probs_df = (pd.DataFrame([words, neg_probs, pos_probs])\n",
    "                         .transpose()\n",
    "                         .rename(columns={0:\"processed word\", 1:\"p_negative\", 2:\"p_positive\"})\n",
    "                         .set_index(\"processed word\"))\n",
    "        return(word_probs_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7959a0b-5588-4be1-bca9-9b66cb0ad2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the sentiment_predictor function\n",
    "\n",
    "test_example_1 = \"O livro que li no s√°bado agradou-me muito, adorei\" # Positive polarity\n",
    "test_example_2 = \"Odeio o est√∫pido do treinador do Sporting nao posso crer\"          # Negative polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbc97570-3c4c-4ac6-a4be-d02d32f4fa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_predictor(test_example_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "114727dc-fcb5-4fa9-b182-bd96b9916ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_predictor(test_example_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a436a0e-633f-473f-915b-19c5b5a24180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_negative</th>\n",
       "      <th>p_positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processed word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>livr</th>\n",
       "      <td>0.413495</td>\n",
       "      <td>0.586505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>li</th>\n",
       "      <td>0.474753</td>\n",
       "      <td>0.525247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sab</th>\n",
       "      <td>0.442441</td>\n",
       "      <td>0.557559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agrad</th>\n",
       "      <td>0.619332</td>\n",
       "      <td>0.380668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ador</th>\n",
       "      <td>0.28682</td>\n",
       "      <td>0.71318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               p_negative p_positive\n",
       "processed word                      \n",
       "livr             0.413495   0.586505\n",
       "li               0.474753   0.525247\n",
       "sab              0.442441   0.557559\n",
       "agrad            0.619332   0.380668\n",
       "ador              0.28682    0.71318"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_predictor(test_example_1, extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaf25245-f617-4815-a20b-39600253cd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_negative</th>\n",
       "      <th>p_positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processed word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>odei</th>\n",
       "      <td>0.67037</td>\n",
       "      <td>0.32963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estup</th>\n",
       "      <td>0.466967</td>\n",
       "      <td>0.533033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trein</th>\n",
       "      <td>0.647502</td>\n",
       "      <td>0.352498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sporting</th>\n",
       "      <td>0.363916</td>\n",
       "      <td>0.636084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nao</th>\n",
       "      <td>0.587917</td>\n",
       "      <td>0.412083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0.569527</td>\n",
       "      <td>0.430473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cr</th>\n",
       "      <td>0.67037</td>\n",
       "      <td>0.32963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               p_negative p_positive\n",
       "processed word                      \n",
       "odei              0.67037    0.32963\n",
       "estup            0.466967   0.533033\n",
       "trein            0.647502   0.352498\n",
       "sporting         0.363916   0.636084\n",
       "nao              0.587917   0.412083\n",
       "pos              0.569527   0.430473\n",
       "cr                0.67037    0.32963"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_predictor(test_example_2, extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f9923-e4ee-417e-aba8-f3d8cddc9e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb0e46-5b29-4ce4-96ee-c56adf2dce9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
